#!/usr/bin/env python3
"""
æµ‹è¯•Web Searchå·¥å…·ä¿®å¤æ•ˆæœ
ä½œè€…: Emink
"""

import asyncio
import json
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from enhanced_server_pure import (
    search_and_extract,
    search_duckduckgo,
    unlock_web_content,
)


async def test_search_basic():
    """æµ‹è¯•åŸºæœ¬æœç´¢åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•åŸºæœ¬æœç´¢åŠŸèƒ½...")

    query = "Python programming tutorial"
    results = await search_duckduckgo(query, num_results=5)

    print(f"æœç´¢æŸ¥è¯¢: {query}")
    print(f"ç»“æœæ•°é‡: {len(results)}")

    if results and not results[0].get("error"):
        print("âœ… æœç´¢æˆåŠŸ!")
        for i, result in enumerate(results[:3]):
            print(f"  {i+1}. {result['title'][:50]}...")
            print(f"     URL: {result['url'][:60]}...")
            print(f"     æ‘˜è¦: {result['snippet'][:80]}...")
    else:
        print("âŒ æœç´¢å¤±è´¥:", results[0].get("error") if results else "æ— ç»“æœ")

    return results


async def test_search_with_extraction():
    """æµ‹è¯•æœç´¢+å†…å®¹æå–åŠŸèƒ½"""
    print("\nğŸ“„ æµ‹è¯•æœç´¢+å†…å®¹æå–åŠŸèƒ½...")

    query = "artificial intelligence 2024"
    result = await search_and_extract(query, num_results=3, extract_content=True)

    print(f"æœç´¢æŸ¥è¯¢: {query}")
    print(f"æœç´¢ç»“æœæ•°: {result['summary']['search_results_count']}")
    print(f"å†…å®¹æå–å°è¯•: {result['summary']['content_extractions_attempted']}")
    print(f"å†…å®¹æå–æˆåŠŸ: {result['summary']['content_extractions_successful']}")

    if result["extracted_content"]:
        print("âœ… å†…å®¹æå–æˆåŠŸ!")
        for content in result["extracted_content"]:
            if content.get("status") == "success":
                print(f"  - {content['title'][:50]}...")
                print(f"    å†…å®¹é•¿åº¦: {len(content['content'])} å­—ç¬¦")
                print(f"    å†…å®¹é¢„è§ˆ: {content['content'][:100]}...")
            else:
                print(f"  - æå–å¤±è´¥: {content.get('error', 'Unknown error')}")
    else:
        print("âŒ å†…å®¹æå–å¤±è´¥")

    return result


async def test_content_extraction():
    """æµ‹è¯•å•ç‹¬çš„å†…å®¹æå–åŠŸèƒ½"""
    print("\nğŸŒ æµ‹è¯•å†…å®¹æå–åŠŸèƒ½...")

    # æµ‹è¯•ä¸€ä¸ªå¸¸è§çš„ç½‘ç«™
    test_url = "https://www.python.org/about/"

    print(f"æµ‹è¯•URL: {test_url}")
    result = await unlock_web_content(test_url, extract_text=True)

    if result.get("status") == "success":
        print("âœ… å†…å®¹æå–æˆåŠŸ!")
        print(f"  æ ‡é¢˜: {result['title']}")
        print(f"  å†…å®¹é•¿åº¦: {len(result.get('content', ''))} å­—ç¬¦")
        print(f"  ä½œè€…: {result['meta'].get('author', 'N/A')}")
        print(f"  æè¿°: {result['meta'].get('description', 'N/A')[:80]}...")
        print(f"  å†…å®¹é¢„è§ˆ: {result['content'][:200]}...")
    else:
        print("âŒ å†…å®¹æå–å¤±è´¥:", result.get("error"))

    return result


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•Web Searchå·¥å…·ä¿®å¤æ•ˆæœ\n")

    try:
        # æµ‹è¯•1: åŸºæœ¬æœç´¢
        await test_search_basic()

        # æµ‹è¯•2: æœç´¢+å†…å®¹æå–
        await test_search_with_extraction()

        # æµ‹è¯•3: å†…å®¹æå–
        await test_content_extraction()

        print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
